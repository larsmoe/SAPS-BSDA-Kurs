{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Willkommen zum fünften Python-Problem Set in diesem Modul!  \n",
    "Sie finden hier zwei Aufgaben (*Exercise 9* und *Exercise 10*) zu Inhalten aus Kapitel 4 *Text Mining* - konkret zu den Teilen 4.1 *Einführung und Grundlagen* und 4.2 *Topic Analysis und Topic Mining*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9 -- Einführung und Grundlagen in Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel dieser *Exercise* ist die Heranführung an die grundlegenden Schritte des Text Mining. Hierzu gehört zunächst das **Einlesen von Textdaten** und die **Konvertierung der Textdaten** in maschinenlesbare Form, in unserem Fall als Document Term Matrix (DTM).  \n",
    "\n",
    "Die DTM eines Dokumentencorpus beinhaltet in den Zeilen die entsprechenden Dokumente des Corpus, während die Spalten alle verschiedenen Wörter des gesamten Corpus darstellen. Die Einträge der DTM beschreiben dabei das Vorkommen eines Wortes innerhalb eines Dokumentes. Informationen zum *i*-ten Dokument des Corpus erhalten wir daher in der *i*-ten Zeile der DTM. Sie entspricht dem im Skript eingeführten **Dokumentvektor** des Vektorraummodells. In der folgenden *Infobox* finden Sie eine kurze Wiederholung zu Dokumentvektoren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info: Wiederholung Dokumentvektoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einträge von Nullen im Dokumentvektor beschreiben, dass die entsprechenden Wörter, die in den Spalten dargestellt werden, nicht im Dokument vorhanden sind. Einträge größer als 0 bedeuten hingegen, dass die entsprechenden Wörter im Dokument enthalten sind. Welche genauen Werte die positiven Einträge annehmen können, hängt von der gewählten Ausprägung des Vektormodells ab. Bei einer **binären Repräsentation** können Einträge nur die Werte 0 oder 1 annehmen. Diese Art der Repräsentation wird bevorzugt für Sentiment Analysis verwendet, da das Vorkommen eines einzelnen Wortes in diesem Kontext wichtiger sein kann als z.B. die Anzahl des Vorkommens (Manning et al. (2008)). Möchte man die Anzahl der Wörter innerhalb eines Dokumentes berücksichtigen wählt man für die Repräsentation der Werte in der DTM die **Termfrequenz (tf)**. Eine weitere Repräsentation der Einträge der DTM ist die **invertierte Termfrequenz (tf-idf)**, bei der die Anzahl des Vorkommens von Wörtern innerhalb eines Dokument normiert mit der Anzahl des Vorkommens von den Wörtern über die Dokumente betrachtet wird.\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "Im Folgenden werden wir die DTM mit den drei verschiedenen Repräsentationsmethoden von Dokumenten, die Sie im Skript kennengelernt haben (**binäre Repräsentation**, **Termfrequenz** und **invertierte Termfrequenz**), für eine Sammlung von Textdokumenten erstellen und betrachten. Die hierzu verwendeten Textdaten wurden erstmals von Pang und Lee (2004) für eine Sentiment Analysis benutzt. Der verwendete Datensatz besteht aus 1.000 positiven und 1.000 negativen Filmkritiken, wobei jede Filmkritik in einer separaten Datei gespeichert ist. Die Filmkritiken, die eine positive Grundstimmung gegenüber einem Film ausdrücken, liegen im Ordner *\"pos\"*, wohingegen Filmkritiken, die eine negative Grundstimmung ausdrücken, im Ordner *\"neg\"* abgelegt sind. Die Einteilung der Filmkritiken in die Klassen *positiv* und *negativ* wird allerdings erst für die Verwendung von Klassifizierungsalgorithmen eine Bedeutung spielen.\n",
    "\n",
    "Führen Sie den folgenden Code aus, um die Daten in R einzulesen, sie für die spätere Erstellung einer DTM aufzubereiten und beispielhaft die Eigenschaften und den Inhalt eines Elements aus jedem der beiden Datensätze einsehen zu können.  \n",
    "*Hinweis: Der Code in diesem Problem Set ist relativ rechenintensiv. Wundern Sie sich daher nicht, falls Sie nach der Eingabe eines korrekten Codes einige Sekunden warten müssen.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you've got mail works alot better than it deserves to . \n",
      "in order to make the film a success , all they had to do was cast two extremely popular and attractive stars , have them share the screen for about two hours and then collect the profits . \n",
      "no real acting was involved and there is not an original or inventive bone in it's body ( it's basically a complete re-shoot of the shop around the corner , only adding a few modern twists ) . \n",
      "essentially , it goes against and defies all concepts of good contemporary filmmaking . \n",
      "it's overly sentimental and at times terribly mushy , not to mention very manipulative . \n",
      "but oh , how enjoyable that manipulation is . \n",
      "but there must be something other than the casting and manipulation that makes the movie work as well as it does , because i absolutely hated the previous ryan/hanks teaming , sleepless in seattle . \n",
      "it couldn't have been the directing , because both films were helmed by the same woman . \n",
      "i haven't quite yet figured out what i liked so much about you've got mail , but then again , is that really important ? \n",
      "if you like something so much , why even question it ? \n",
      "again , the storyline is as cliched as they come . \n",
      "tom hanks plays joe fox , the insanely likeable owner of a discount book chain and meg ryan plays kathleen kelley , the even more insanely likeable proprietor of a family-run children's book shop called , in a nice homage , the shop around the corner . \n",
      "fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business . \n",
      "little do they know , they are already in love with each other over the internet , only neither party knows the other person's true identity . \n",
      "the rest of the story isn't important because all it does is serve as a mere backdrop for the two stars to share the screen . \n",
      "sure , there are some mildly interesting subplots , but they all fail in comparison to the utter cuteness of the main relationship . \n",
      "all of this , of course , leads up to the predictable climax . \n",
      "but as foreseeable as the ending is , it's so damn cute and well-done that i doubt any movie in the entire year contains a scene the evokes as much pure joy as this part does . \n",
      "when ryan discovers the true identity of her online love , i was filled with such , for lack of a better word , happiness that for the first time all year , i actually left the theater smiling . \n",
      "\n",
      "it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . \n",
      "based on the late 1960's television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . \n",
      "however , things go wrong as evidence gets stolen and they are immediately under suspicion . \n",
      "of course , the ads make it seem like so much more . \n",
      "quick cuts , cool music , claire dane's nice hair and cute outfits , car chases , stuff blowing up , and the like . \n",
      "sounds like a cool movie , does it not ? \n",
      "after the first fifteen minutes , it quickly becomes apparent that it is not . \n",
      "the mod squad is certainly a slick looking production , complete with nice hair and costumes , but that simply isn't enough . \n",
      "the film is best described as a cross between an hour-long cop show and a music video , both stretched out into the span of an hour and a half . \n",
      "and with it comes every single clich ? . \n",
      "it doesn't really matter that the film is based on a television show , as most of the plot elements have been recycled from everything we've already seen . \n",
      "the characters and acting is nothing spectacular , sometimes even bordering on wooden . \n",
      "claire danes and omar epps deliver their lines as if they are bored , which really transfers onto the audience . \n",
      "the only one to escape relatively unscathed is giovanni ribisi , who plays the resident crazy man , ultimately being the only thing worth watching . \n",
      "unfortunately , even he's not enough to save this convoluted mess , as all the characters don't do much apart from occupying screen time . \n",
      "with the young cast , cool clothes , nice hair , and hip soundtrack , it appears that the film is geared towards the teenage mindset . \n",
      "despite an american 'r' rating ( which the content does not justify ) , the film is way too juvenile for the older mindset . \n",
      "information on the characters is literally spoon-fed to the audience ( would it be that hard to show us instead of telling us ? ) , dialogue is poorly written , and the plot is extremely predictable . \n",
      "the way the film progresses , you likely won't even care if the heroes are in any jeopardy , because you'll know they aren't . \n",
      "basing the show on a 1960's television show that nobody remembers is of questionable wisdom , especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand ( even one that's missing a finger or two ) . \n",
      "the number of times that i checked my watch ( six ) is a clear indication that this film is not one of them . \n",
      "it is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar , judging from the rash of really awful teen-flicks that we've been seeing as of late . \n",
      "avoid this film at all costs . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {\"9\"}\n",
    "#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\n",
    "\n",
    "#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\n",
    "pos_movie_dir = 'pos'\n",
    "neg_movie_dir = 'neg'\n",
    "#Funktion zum Einlesen der Textdateien\n",
    "\n",
    "def read_txt_in_dir(directory):\n",
    "    dir_txt = []\n",
    "    for filename in os.listdir(directory):\n",
    "        with open(os.path.join(directory, filename)) as file:\n",
    "            txt = file.read()\n",
    "            dir_txt.append(txt)\n",
    "    return dir_txt\n",
    "#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\n",
    "pos_movies = read_txt_in_dir(pos_movie_dir)\n",
    "neg_movies = read_txt_in_dir(neg_movie_dir)\n",
    "#Alle Daten in einem  Vektor zusammenfassen\n",
    "all_movies = pd.DataFrame({'pos_movies': pos_movies, 'neg_movies': neg_movies})\n",
    "#Details über das dritte Element der Datensätze anzeigen\n",
    "\n",
    "\n",
    "#Ausgabe des dritten Elements der Datensätze\n",
    "print(pos_movies[2])\n",
    "#- - -\n",
    "print(neg_movies[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen, wurden die in den Ordnern *\"pos\"* und *\"neg\"* enthaltenen Dateien in Objekten der Klasse *\"VCorpus\"* gespeichert. Hierbei handelt es sich um Listen, deren Elemente jeweils zwei Spalten beinhalten: *meta* und *content*. Während die Spalte *meta* Informationen über das Dokument enthält, wie beispielsweise den Dateinamen im Feld *id*, gibt die Spalte *content* den Inhalt des Textdokumentes zeilenweise aus. Entsprechend  erfolgen der Zugriff auf Informationen über einzelne Elemente der Datensätze (*...$meta*) und das Anzeigen des Inhaltes (*...$content*) jeweils mithilfe von doppelten eckigen Klammern *[[]]*, da in R der Zugriff auf Listenelemente allgemein über doppelte eckige Klammern erfolgt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Termfrequenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um nun mit den Daten weiterarbeiten zu können, sollen diese in Form einer DTM dargestellt werden. Konkret wollen wir hier als Gewichte die Termfrequenzen verwenden. Hierzu bietet das package \"tm\" den Befehl **DocumentTermMatrix(x, control = list(stopwords, removeNumbers, removePunctuation, tolower, stripWhitespace, stemming))**. Dabei nimmt die Funktion für *x* ein Objekt der Klasse *\"Vcorpus\"* entgegen, welches die Textdokumente beinhaltet. Die Inputvariablen im Argument *control* stellen boolesche Ausdrücke dar:  \n",
    "* Mithilfe von *stopwords* kann festgelegt werden, ob die im Text enthaltenen Stoppwörter entfernt werden sollen. Stoppwörter sind Wörter ohne inhaltliche Relevanz, wie im Deutschen z.B. \"und\",\"so\",\"der\",\"die\" oder \"das\". Wenn *stopwords* auf *FALSE* gesetzt wird, bleiben diese in der DTM enthalten.  \n",
    "* Durch *TRUE* bei *removeNumbers* werden alle im Text enthaltenen Zahlen entfernt.  \n",
    "* *removePunctuation* entfernt, falls es auf *TRUE* gesetzt wird, die Interpunktion im Text.  \n",
    "* Die Variable  *tolower* wandelt alle Buchstaben in Kleinbuchstaben um, wenn sie auf *TRUE* gesetzt wird.  \n",
    "* Mittels *TRUE* beim Befehl *stripWhitespace* wird sichergestellt, dass überflüssige aufeinanderfolgende Leerzeichen zu einem Leerzeichen komprimiert werden.  \n",
    "* Durch die Variable *stemming* kann festgelegt werden, ob Wörter im Text auf ihren Wortstamm reduziert werden sollen (*TRUE*) oder nicht (*FALSE*). Das Komprimieren von Wörtern auf ihre Stämme dient vor allem der Dimensionsreduktion und kann je nach Anwendungsfall sinnvoll sein oder nicht. Für das Bilden der Wortstämme wird intern das R-Package *\"SnowballC\"* verwendet, welches auf den Porter-Stemming-Algorithmus zurückgreift.\n",
    "\n",
    "Per Default sind alle Befehle auf *FALSE* gesetzt und die DTM wird mit der absoluten Termfrequenz **tf** dargestellt.  \n",
    "- - -\n",
    "*Aufgabe*: Wenden Sie den Befehl *DocumentTermMatrix()* auf den gesamten Datensatz *full_corpus* (ein *VCorpus*-Objekt) an, sodass Stoppwörter, Zahlen und Interpunktion entfernt werden, alle Wörter in Kleinbuchstaben konvertiert werden, unnötige Leerzeichen entfernt werden und **keine** Wortstämme gebildet werden. Bitte beachten Sie auch, die Parameter in der genannten Reihenfolge anzugeben. Geben Sie anschließend die erzeugte DTM mit dem Befehl *print()* aus.\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "pos_movies_vectorized = vectorizer.fit_transform(pos_movies)\n",
    "neg_movies_vetorized = vectorizer.fit_transform(neg_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DTM_tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5332/2434352482.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Wenden Sie den oben beschriebenen Befehl an und speichern Sie das\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Ergebnis in der Variable DTM_tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m DTM_tf <- DocumentTermMatrix(x=full_corpus,\n\u001b[0m\u001b[0;32m      5\u001b[0m                           control=list(\n\u001b[0;32m      6\u001b[0m                             \u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTRUE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DTM_tf' is not defined"
     ]
    }
   ],
   "source": [
    "# {\"9_2\"}\n",
    "#Wenden Sie den oben beschriebenen Befehl an und speichern Sie das\n",
    "#Ergebnis in der Variable DTM_tf\n",
    "DTM_tf <- DocumentTermMatrix(x=full_corpus,\n",
    "                          control=list(\n",
    "                            stopwords=TRUE,\n",
    "                            removeNumbers=TRUE,\n",
    "                            removePunctuation=TRUE,\n",
    "                            tolower=TRUE,\n",
    "                            stripWhitespace=TRUE,\n",
    "                            stemming=FALSE))\n",
    "\n",
    "#Geben Sie anschließend das Ergebnis für die DTM_tf \n",
    "#mit dem Befehl print() aus\n",
    "print(DTM_tf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bed862baa169bd35b57b2a485b7961cf7d1bd32d9b549d4e10480d14566cc8ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
