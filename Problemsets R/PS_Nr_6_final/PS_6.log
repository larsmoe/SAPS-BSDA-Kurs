{"type":["init_ps"],"time":["2017-07-03 15:57:39"],"user":["default_user"],"umph":[1499090259.2904],"ok":[true]}
,
{"type":["init_ps"],"time":["2017-07-03 16:44:30"],"user":["default_user"],"umph":[1499093070.282],"ok":[true]}
,
{"type":["init_ps"],"time":["2017-07-03 16:44:55"],"user":["default_user"],"umph":[1499093095.7941],"ok":[true]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:38"],"user":["default_user"],"umph":[1499093138.9201],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:41"],"user":["default_user"],"umph":[1499093141.7295],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:44"],"user":["default_user"],"umph":[1499093144.704],"ok":[true],"chunk":[3],"ex":[1],"e.ind":[0],"code":["#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(x=DTM_tf)\n\n#Aufteilung in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:47"],"user":["default_user"],"umph":[1499093147.8377],"ok":[true],"chunk":[4],"ex":[1],"e.ind":[0],"code":["#Verwenden Sie die Funktion naiveBayes(), um mit den Daten aus \n#den Variablen posts_training und posts_traininglabel den Naive Bayes\n#-Klassifikator zu bilden und speichern Sie das Ergebnis in der Variablen\n#nB_classifier\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Verwenden Sie Ihren eben erzeugten Naive Bayes-Klassifikator\n#in der Funktion predict() um die Klassen für die Daten in \n#der Variable posts_test vorherzusagen und speichern Sie Ihr\n#Ergebnis in der Variablen nB_predicted\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Lassen Sie sich das Ergebnis der Klassifikation ausgeben\nnB_predicted"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:51"],"user":["default_user"],"umph":[1499093151.7761],"ok":[true],"chunk":[5],"ex":[1],"e.ind":[0],"code":["#Erzeugen Sie eine Confusion Matrix mit dem Befehl table()\n#und speichern Sie diese in der Variable nB_confMat\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\n#Lassen Sie sich nB_confMat ausgeben\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:53"],"user":["default_user"],"umph":[1499093153.7259],"ok":[true],"chunk":[6],"ex":[1],"e.ind":[0],"code":["#Berechnung von Precision und Recall für die Klasse D\n#Auf Basis der Confusion Matrix\nnB_precision_D <- nB_confMat[1,1]/sum(nB_confMat[,1])\nprint(c(\"Precision für die Klasse Deutsch:\", nB_precision_D))\n\nnB_recall_D <- nB_confMat[1,1]/sum(nB_confMat[1,])\nprint(c(\"Recall für die Klasse Deutsch:\", nB_recall_D))\n\n#Berechnen der F-Measure mit beta = 1 für die Klasse D\n#Auf Basis von Precision und Recall\nbeta <- 1\nnB_F1_D <- ((beta^2+1)*nB_precision_D*nB_recall_D)/(beta^2*nB_precision_D+nB_recall_D)\nprint(c(\"F1-Measure für die Klasse Deutsch:\", nB_F1_D))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:45:56"],"user":["default_user"],"umph":[1499093156.4714],"ok":[true],"chunk":[7],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= stopwords(kind=\"de\"),\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)\n\n#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(DTM_tf)\n\n#Aufteilen in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]\n\n#Erzeugen des Naive Bayes-Klassifikators\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Anwenden des Naive Bayes-Klassifikators auf die Testdaten\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Ausgabe der Ergebnisse der Klassifikation\nnB_predicted\n\n#Berechnung und Ausgabe der Confusion Matrix\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:46:06"],"user":["default_user"],"umph":[1499093166.2414],"ok":[true],"chunk":[8],"ex":[1],"e.ind":[0],"code":["\n#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\npos_movie<-DirSource(directory = \"./pos\")\nneg_movie<-DirSource(directory = \"./neg\")\n#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\npos_corpus<-VCorpus(x=pos_movie)\nneg_corpus<-VCorpus(x=neg_movie)\n#Verwendete Trainings- und Testdaten in einem  Vektor zusammenfassen\n#(100 positive und 100 negative Bewertungen)\nfull_corpus<-c(pos_corpus[401:500],neg_corpus[401:500])\n#Den Daten das entsprechende Klassenlabel zuordnen\nsentiment_label <- c(rep(x = \"positive\", times = 100), \n                    rep(x = \"negative\", times = 100))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:46:13"],"user":["default_user"],"umph":[1499093173.1798],"ok":[true],"chunk":[9],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM mit tfidf-Gewichtung\nDTM_tfidf <- DocumentTermMatrix(full_corpus,\n                              control = list(\n                                stopwords = TRUE,\n                                removeNumbers = TRUE,\n                                removePunctuation = TRUE,\n                                tolower = TRUE,\n                                stripWhitespace = TRUE,                                \n                                stemming = FALSE,\n                                weighting=function(x)\n                                 weightTfIdf(x)))\n\n#Begutachtung des Aufbaus der DTM_tfidf\nprint(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:46:22"],"user":["default_user"],"umph":[1499093182.1494],"ok":[true],"chunk":[10],"ex":[1],"e.ind":[0],"code":["#Mithilfe der Funktion norm_eucl soll die DTM mit dem euklidischem \n#Distanzmaß normiert werden\nnorm_eucl <- function(x){\n   x/apply(x,1,function(x) sum(x^2)^.5)\n}\n\n#Wenden Sie die Funktion norm_eucl() auf die DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf<-norm_eucl(x=DTM_tfidf)\n\n#Wenden Sie die Funktion as.matrix() auf die neue DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf = as.matrix(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:46:25"],"user":["default_user"],"umph":[1499093185.2048],"ok":[true],"chunk":[11],"ex":[1],"e.ind":[0],"code":["#Laden des benötigten Packages 'caret', um die nachfolgenden Methoden\n#verwenden zu können\nlibrary(caret)\n\n#Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\nset.seed(1111)\n\n#Elemente des Sentimentlabel-Vektors zufällig in drei Gruppen aufteilen\nindxs<-createFolds(y=sentiment_label,k=3)\n\n#Testdaten gemäß der Aufteilung definieren\ntestset<-DTM_tfidf[indxs[[1]],]\n#Labels der Testdaten\ntestlabels <- sentiment_label[indxs[[1]]]\n\n#Trainingsdaten gemäß der Aufteilung definieren\ntrainingset<- DTM_tfidf[-indxs[[1]],]\n#Labels der Trainingsdaten\ntraininglabels <- sentiment_label[-indxs[[1]]]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:46:31"],"user":["default_user"],"umph":[1499093191.8363],"ok":[true],"chunk":[12],"ex":[1],"e.ind":[0],"code":["#Wenden Sie die Funktion knn wie oben beschrieben an\n#und speichern Sie das Ergebnis in der Variable knn_predicted_single\nknn_predicted_single <- knn(train = trainingset, test =testset,\n                            cl =  traininglabels, k = 12)\n"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:46:57"],"user":["default_user"],"umph":[1499093217.4221],"ok":[true],"chunk":[13],"ex":[1],"e.ind":[0],"code":["#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:47:03"],"user":["default_user"],"umph":[1499093223.8208],"ok":[true],"chunk":[14],"ex":[1],"e.ind":[0],"code":["#Laden der benötigten Packages 'class' und 'caret', um die nachfolgenden Methoden verwenden zu können\nlibrary(class)\nlibrary(caret)\n#Cross-Validation für k Nearest Neighbors machen\ncrossvalidate <- function(DTM,label,numberFolds,k,seed){\n  #Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\n  set.seed(seed)\n  #createFolds benötigt das package \"caret\"\n  indxs<-createFolds(y=label,k=numberFolds)\n  for(i in 1:numberFolds){\n    #Trainingsdaten\n    trainingset<- DTM[-indxs[[i]],]\n    #Labels der Trainingsdaten\n    traininglabels <- label[-indxs[[i]]]\n    #Testdaten\n    testset<-DTM[indxs[[i]],]\n    #Labels der Testdaten\n    testlabels <- label[indxs[[i]]]\n    \n    ##k Nearest Neighbor Classifier\n    #knn ausführen\n    knn_predicted <- knn(train = trainingset, test =testset, cl =  traininglabels, k = k)\n    \n    #Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\n    knn_confMat <- table(\"Klasse\" = testlabels, \"Klassifiziert als\" = knn_predicted)\n    print(knn_confMat)\n    \n    #Precision der Klasse \"positive\" für jeden Durchlauf berechnen\n    knn_precision_pos <- knn_confMat[2,2]/sum(knn_confMat[,2])\n    print(c(\"Precision:\", knn_precision_pos))\n    \n    #Recall der Klasse \"positive\"  für jeden Durchlauf berechnen\n    knn_recall_pos <- knn_confMat[2,2]/sum(knn_confMat[2,])\n    print(c(\"Recall:\", knn_recall_pos))\n    \n    #F-1 Measure mit beta = 1 der Klasse \"positive\" für jeden Durchlauf berechnen\n    beta <- 1\n    knn_F1_pos <- ((beta^2+1)*knn_precision_pos*knn_recall_pos)/(beta^2*knn_precision_pos+knn_recall_pos)\n    print(c(\"F1-Measure:\", knn_F1_pos))\n  }\n}"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 16:47:14"],"user":["default_user"],"umph":[1499093234.2326],"ok":[true],"chunk":[15],"ex":[1],"e.ind":[0],"code":["#Rufen Sie die Funktion crossvalidate() mit den beschriebenen Parametern auf\ncrossvalidate(DTM = DTM_tfidf, label = sentiment_label, numberFolds = 3, k = 12, seed = 1111)"],"message":[""]}
,
{"type":["init_ps"],"time":["2017-07-03 16:51:01"],"user":["default_user"],"umph":[1499093461.2777],"ok":[true]}
,
{"type":["init_ps"],"time":["2017-07-03 17:18:15"],"user":["default_user"],"umph":[1499095095.6789],"ok":[true]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:20"],"user":["default_user"],"umph":[1499095100.8648],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:23"],"user":["default_user"],"umph":[1499095103.5552],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:26"],"user":["default_user"],"umph":[1499095106.3205],"ok":[true],"chunk":[3],"ex":[1],"e.ind":[0],"code":["#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(x=DTM_tf)\n\n#Aufteilung in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:29"],"user":["default_user"],"umph":[1499095109.1177],"ok":[true],"chunk":[4],"ex":[1],"e.ind":[0],"code":["#Verwenden Sie die Funktion naiveBayes(), um mit den Daten aus \n#den Variablen posts_training und posts_traininglabel den Naive Bayes\n#-Klassifikator zu bilden und speichern Sie das Ergebnis in der Variablen\n#nB_classifier\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Verwenden Sie Ihren eben erzeugten Naive Bayes-Klassifikator\n#in der Funktion predict() um die Klassen für die Daten in \n#der Variable posts_test vorherzusagen und speichern Sie Ihr\n#Ergebnis in der Variablen nB_predicted\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Lassen Sie sich das Ergebnis der Klassifikation ausgeben\nnB_predicted"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:31"],"user":["default_user"],"umph":[1499095111.406],"ok":[true],"chunk":[5],"ex":[1],"e.ind":[0],"code":["#Erzeugen Sie eine Confusion Matrix mit dem Befehl table()\n#und speichern Sie diese in der Variable nB_confMat\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\n#Lassen Sie sich nB_confMat ausgeben\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:34"],"user":["default_user"],"umph":[1499095114.3152],"ok":[true],"chunk":[6],"ex":[1],"e.ind":[0],"code":["#Berechnung von Precision und Recall für die Klasse D\n#Auf Basis der Confusion Matrix\nnB_precision_D <- nB_confMat[1,1]/sum(nB_confMat[,1])\nprint(c(\"Precision für die Klasse Deutsch:\", nB_precision_D))\n\nnB_recall_D <- nB_confMat[1,1]/sum(nB_confMat[1,])\nprint(c(\"Recall für die Klasse Deutsch:\", nB_recall_D))\n\n#Berechnen der F-Measure mit beta = 1 für die Klasse D\n#Auf Basis von Precision und Recall\nbeta <- 1\nnB_F1_D <- ((beta^2+1)*nB_precision_D*nB_recall_D)/(beta^2*nB_precision_D+nB_recall_D)\nprint(c(\"F1-Measure für die Klasse Deutsch:\", nB_F1_D))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:36"],"user":["default_user"],"umph":[1499095116.7303],"ok":[true],"chunk":[7],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= stopwords(kind=\"de\"),\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)\n\n#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(DTM_tf)\n\n#Aufteilen in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]\n\n#Erzeugen des Naive Bayes-Klassifikators\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Anwenden des Naive Bayes-Klassifikators auf die Testdaten\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Ausgabe der Ergebnisse der Klassifikation\nnB_predicted\n\n#Berechnung und Ausgabe der Confusion Matrix\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:47"],"user":["default_user"],"umph":[1499095127.6366],"ok":[true],"chunk":[8],"ex":[1],"e.ind":[0],"code":["\n#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\npos_movie<-DirSource(directory = \"./pos\")\nneg_movie<-DirSource(directory = \"./neg\")\n#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\npos_corpus<-VCorpus(x=pos_movie)\nneg_corpus<-VCorpus(x=neg_movie)\n#Verwendete Trainings- und Testdaten in einem  Vektor zusammenfassen\n#(100 positive und 100 negative Bewertungen)\nfull_corpus<-c(pos_corpus[401:500],neg_corpus[401:500])\n#Den Daten das entsprechende Klassenlabel zuordnen\nsentiment_label <- c(rep(x = \"positive\", times = 100), \n                    rep(x = \"negative\", times = 100))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:18:55"],"user":["default_user"],"umph":[1499095135.9946],"ok":[true],"chunk":[9],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM mit tfidf-Gewichtung\nDTM_tfidf <- DocumentTermMatrix(full_corpus,\n                              control = list(\n                                stopwords = TRUE,\n                                removeNumbers = TRUE,\n                                removePunctuation = TRUE,\n                                tolower = TRUE,\n                                stripWhitespace = TRUE,                                \n                                stemming = FALSE,\n                                weighting=function(x)\n                                 weightTfIdf(x)))\n\n#Begutachtung des Aufbaus der DTM_tfidf\nprint(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:04"],"user":["default_user"],"umph":[1499095144.1478],"ok":[true],"chunk":[10],"ex":[1],"e.ind":[0],"code":["#Mithilfe der Funktion norm_eucl soll die DTM mit dem euklidischem \n#Distanzmaß normiert werden\nnorm_eucl <- function(x){\n   x/apply(x,1,function(x) sum(x^2)^.5)\n}\n\n#Wenden Sie die Funktion norm_eucl() auf die DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf<-norm_eucl(x=DTM_tfidf)\n\n#Wenden Sie die Funktion as.matrix() auf die neue DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf = as.matrix(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:07"],"user":["default_user"],"umph":[1499095147.7981],"ok":[true],"chunk":[11],"ex":[1],"e.ind":[0],"code":["#Laden des benötigten Packages 'caret', um die nachfolgenden Methoden\n#verwenden zu können\nlibrary(caret)\n\n#Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\nset.seed(1111)\n\n#Elemente des Sentimentlabel-Vektors zufällig in drei Gruppen aufteilen\nindxs<-createFolds(y=sentiment_label,k=3)\n\n#Testdaten gemäß der Aufteilung definieren\ntestset<-DTM_tfidf[indxs[[1]],]\n#Labels der Testdaten\ntestlabels <- sentiment_label[indxs[[1]]]\n\n#Trainingsdaten gemäß der Aufteilung definieren\ntrainingset<- DTM_tfidf[-indxs[[1]],]\n#Labels der Trainingsdaten\ntraininglabels <- sentiment_label[-indxs[[1]]]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:12"],"user":["default_user"],"umph":[1499095152.683],"ok":[true],"chunk":[12],"ex":[1],"e.ind":[0],"code":["#Wenden Sie die Funktion knn wie oben beschrieben an\n#und speichern Sie das Ergebnis in der Variable knn_predicted_single\nknn_predicted_single <- knn(train = trainingset, test =testset,\n                            cl =  traininglabels, k = 12)\n"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:15"],"user":["default_user"],"umph":[1499095155.4461],"ok":[false],"chunk":[13],"ex":[1],"e.ind":[1],"code":["#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":["You have not yet entered all correct commands."]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:20"],"user":["default_user"],"umph":[1499095160.4478],"ok":[true],"chunk":[13],"ex":[1],"e.ind":[0],"code":["set.seed(1111)\n#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:32"],"user":["default_user"],"umph":[1499095172.0701],"ok":[true],"chunk":[14],"ex":[1],"e.ind":[0],"code":["#Laden der benötigten Packages 'class' und 'caret', um die nachfolgenden Methoden verwenden zu können\nlibrary(class)\nlibrary(caret)\n#Cross-Validation für k Nearest Neighbors machen\ncrossvalidate <- function(DTM,label,numberFolds,k,seed){\n  #Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\n  set.seed(seed)\n  #createFolds benötigt das package \"caret\"\n  indxs<-createFolds(y=label,k=numberFolds)\n  for(i in 1:numberFolds){\n    #Trainingsdaten\n    trainingset<- DTM[-indxs[[i]],]\n    #Labels der Trainingsdaten\n    traininglabels <- label[-indxs[[i]]]\n    #Testdaten\n    testset<-DTM[indxs[[i]],]\n    #Labels der Testdaten\n    testlabels <- label[indxs[[i]]]\n    \n    ##k Nearest Neighbor Classifier\n    #knn ausführen\n    knn_predicted <- knn(train = trainingset, test =testset, cl =  traininglabels, k = k)\n    \n    #Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\n    knn_confMat <- table(\"Klasse\" = testlabels, \"Klassifiziert als\" = knn_predicted)\n    print(knn_confMat)\n    \n    #Precision der Klasse \"positive\" für jeden Durchlauf berechnen\n    knn_precision_pos <- knn_confMat[2,2]/sum(knn_confMat[,2])\n    print(c(\"Precision:\", knn_precision_pos))\n    \n    #Recall der Klasse \"positive\"  für jeden Durchlauf berechnen\n    knn_recall_pos <- knn_confMat[2,2]/sum(knn_confMat[2,])\n    print(c(\"Recall:\", knn_recall_pos))\n    \n    #F-1 Measure mit beta = 1 der Klasse \"positive\" für jeden Durchlauf berechnen\n    beta <- 1\n    knn_F1_pos <- ((beta^2+1)*knn_precision_pos*knn_recall_pos)/(beta^2*knn_precision_pos+knn_recall_pos)\n    print(c(\"F1-Measure:\", knn_F1_pos))\n  }\n}"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:19:39"],"user":["default_user"],"umph":[1499095179.4541],"ok":[true],"chunk":[15],"ex":[1],"e.ind":[0],"code":["#Rufen Sie die Funktion crossvalidate() mit den beschriebenen Parametern auf\ncrossvalidate(DTM = DTM_tfidf, label = sentiment_label, numberFolds = 3, k = 12, seed = 1111)"],"message":[""]}
,
{"type":["init_ps"],"time":["2017-07-03 17:21:06"],"user":["default_user"],"umph":[1499095266.7168],"ok":[true]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:11"],"user":["default_user"],"umph":[1499095271.5923],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:13"],"user":["default_user"],"umph":[1499095273.873],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:16"],"user":["default_user"],"umph":[1499095276.2327],"ok":[true],"chunk":[3],"ex":[1],"e.ind":[0],"code":["#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(x=DTM_tf)\n\n#Aufteilung in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:18"],"user":["default_user"],"umph":[1499095278.7167],"ok":[true],"chunk":[4],"ex":[1],"e.ind":[0],"code":["#Verwenden Sie die Funktion naiveBayes(), um mit den Daten aus \n#den Variablen posts_training und posts_traininglabel den Naive Bayes\n#-Klassifikator zu bilden und speichern Sie das Ergebnis in der Variablen\n#nB_classifier\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Verwenden Sie Ihren eben erzeugten Naive Bayes-Klassifikator\n#in der Funktion predict() um die Klassen für die Daten in \n#der Variable posts_test vorherzusagen und speichern Sie Ihr\n#Ergebnis in der Variablen nB_predicted\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Lassen Sie sich das Ergebnis der Klassifikation ausgeben\nnB_predicted"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:20"],"user":["default_user"],"umph":[1499095280.7834],"ok":[true],"chunk":[5],"ex":[1],"e.ind":[0],"code":["#Erzeugen Sie eine Confusion Matrix mit dem Befehl table()\n#und speichern Sie diese in der Variable nB_confMat\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\n#Lassen Sie sich nB_confMat ausgeben\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:22"],"user":["default_user"],"umph":[1499095282.9962],"ok":[true],"chunk":[6],"ex":[1],"e.ind":[0],"code":["#Berechnung von Precision und Recall für die Klasse D\n#Auf Basis der Confusion Matrix\nnB_precision_D <- nB_confMat[1,1]/sum(nB_confMat[,1])\nprint(c(\"Precision für die Klasse Deutsch:\", nB_precision_D))\n\nnB_recall_D <- nB_confMat[1,1]/sum(nB_confMat[1,])\nprint(c(\"Recall für die Klasse Deutsch:\", nB_recall_D))\n\n#Berechnen der F-Measure mit beta = 1 für die Klasse D\n#Auf Basis von Precision und Recall\nbeta <- 1\nnB_F1_D <- ((beta^2+1)*nB_precision_D*nB_recall_D)/(beta^2*nB_precision_D+nB_recall_D)\nprint(c(\"F1-Measure für die Klasse Deutsch:\", nB_F1_D))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:26"],"user":["default_user"],"umph":[1499095286.4144],"ok":[true],"chunk":[7],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= stopwords(kind=\"de\"),\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)\n\n#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(DTM_tf)\n\n#Aufteilen in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]\n\n#Erzeugen des Naive Bayes-Klassifikators\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Anwenden des Naive Bayes-Klassifikators auf die Testdaten\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Ausgabe der Ergebnisse der Klassifikation\nnB_predicted\n\n#Berechnung und Ausgabe der Confusion Matrix\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:35"],"user":["default_user"],"umph":[1499095295.7107],"ok":[true],"chunk":[8],"ex":[1],"e.ind":[0],"code":["\n#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\npos_movie<-DirSource(directory = \"./pos\")\nneg_movie<-DirSource(directory = \"./neg\")\n#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\npos_corpus<-VCorpus(x=pos_movie)\nneg_corpus<-VCorpus(x=neg_movie)\n#Verwendete Trainings- und Testdaten in einem  Vektor zusammenfassen\n#(100 positive und 100 negative Bewertungen)\nfull_corpus<-c(pos_corpus[401:500],neg_corpus[401:500])\n#Den Daten das entsprechende Klassenlabel zuordnen\nsentiment_label <- c(rep(x = \"positive\", times = 100), \n                    rep(x = \"negative\", times = 100))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:42"],"user":["default_user"],"umph":[1499095302.1313],"ok":[true],"chunk":[9],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM mit tfidf-Gewichtung\nDTM_tfidf <- DocumentTermMatrix(full_corpus,\n                              control = list(\n                                stopwords = TRUE,\n                                removeNumbers = TRUE,\n                                removePunctuation = TRUE,\n                                tolower = TRUE,\n                                stripWhitespace = TRUE,                                \n                                stemming = FALSE,\n                                weighting=function(x)\n                                 weightTfIdf(x)))\n\n#Begutachtung des Aufbaus der DTM_tfidf\nprint(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:50"],"user":["default_user"],"umph":[1499095310.2457],"ok":[true],"chunk":[10],"ex":[1],"e.ind":[0],"code":["#Mithilfe der Funktion norm_eucl soll die DTM mit dem euklidischem \n#Distanzmaß normiert werden\nnorm_eucl <- function(x){\n   x/apply(x,1,function(x) sum(x^2)^.5)\n}\n\n#Wenden Sie die Funktion norm_eucl() auf die DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf<-norm_eucl(x=DTM_tfidf)\n\n#Wenden Sie die Funktion as.matrix() auf die neue DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf = as.matrix(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:52"],"user":["default_user"],"umph":[1499095312.8905],"ok":[true],"chunk":[11],"ex":[1],"e.ind":[0],"code":["#Laden des benötigten Packages 'caret', um die nachfolgenden Methoden\n#verwenden zu können\nlibrary(caret)\n\n#Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\nset.seed(1111)\n\n#Elemente des Sentimentlabel-Vektors zufällig in drei Gruppen aufteilen\nindxs<-createFolds(y=sentiment_label,k=3)\n\n#Testdaten gemäß der Aufteilung definieren\ntestset<-DTM_tfidf[indxs[[1]],]\n#Labels der Testdaten\ntestlabels <- sentiment_label[indxs[[1]]]\n\n#Trainingsdaten gemäß der Aufteilung definieren\ntrainingset<- DTM_tfidf[-indxs[[1]],]\n#Labels der Trainingsdaten\ntraininglabels <- sentiment_label[-indxs[[1]]]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:21:57"],"user":["default_user"],"umph":[1499095317.5376],"ok":[true],"chunk":[12],"ex":[1],"e.ind":[0],"code":["#Wenden Sie die Funktion knn wie oben beschrieben an\n#und speichern Sie das Ergebnis in der Variable knn_predicted_single\nknn_predicted_single <- knn(train = trainingset, test =testset,\n                            cl =  traininglabels, k = 12)\n"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:22:00"],"user":["default_user"],"umph":[1499095320.7766],"ok":[true],"chunk":[13],"ex":[1],"e.ind":[0],"code":["set.seed(1111)\n#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":[""]}
,
{"type":["init_ps"],"time":["2017-07-03 17:23:54"],"user":["default_user"],"umph":[1499095434.0764],"ok":[true]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:02"],"user":["default_user"],"umph":[1499095442.525],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:04"],"user":["default_user"],"umph":[1499095444.6663],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:06"],"user":["default_user"],"umph":[1499095446.6623],"ok":[true],"chunk":[3],"ex":[1],"e.ind":[0],"code":["#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(x=DTM_tf)\n\n#Aufteilung in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:08"],"user":["default_user"],"umph":[1499095448.9283],"ok":[true],"chunk":[4],"ex":[1],"e.ind":[0],"code":["#Verwenden Sie die Funktion naiveBayes(), um mit den Daten aus \n#den Variablen posts_training und posts_traininglabel den Naive Bayes\n#-Klassifikator zu bilden und speichern Sie das Ergebnis in der Variablen\n#nB_classifier\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Verwenden Sie Ihren eben erzeugten Naive Bayes-Klassifikator\n#in der Funktion predict() um die Klassen für die Daten in \n#der Variable posts_test vorherzusagen und speichern Sie Ihr\n#Ergebnis in der Variablen nB_predicted\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Lassen Sie sich das Ergebnis der Klassifikation ausgeben\nnB_predicted"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:11"],"user":["default_user"],"umph":[1499095451.294],"ok":[true],"chunk":[5],"ex":[1],"e.ind":[0],"code":["#Erzeugen Sie eine Confusion Matrix mit dem Befehl table()\n#und speichern Sie diese in der Variable nB_confMat\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\n#Lassen Sie sich nB_confMat ausgeben\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:13"],"user":["default_user"],"umph":[1499095453.2114],"ok":[true],"chunk":[6],"ex":[1],"e.ind":[0],"code":["#Berechnung von Precision und Recall für die Klasse D\n#Auf Basis der Confusion Matrix\nnB_precision_D <- nB_confMat[1,1]/sum(nB_confMat[,1])\nprint(c(\"Precision für die Klasse Deutsch:\", nB_precision_D))\n\nnB_recall_D <- nB_confMat[1,1]/sum(nB_confMat[1,])\nprint(c(\"Recall für die Klasse Deutsch:\", nB_recall_D))\n\n#Berechnen der F-Measure mit beta = 1 für die Klasse D\n#Auf Basis von Precision und Recall\nbeta <- 1\nnB_F1_D <- ((beta^2+1)*nB_precision_D*nB_recall_D)/(beta^2*nB_precision_D+nB_recall_D)\nprint(c(\"F1-Measure für die Klasse Deutsch:\", nB_F1_D))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:15"],"user":["default_user"],"umph":[1499095455.3738],"ok":[true],"chunk":[7],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= stopwords(kind=\"de\"),\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)\n\n#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(DTM_tf)\n\n#Aufteilen in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]\n\n#Erzeugen des Naive Bayes-Klassifikators\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Anwenden des Naive Bayes-Klassifikators auf die Testdaten\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Ausgabe der Ergebnisse der Klassifikation\nnB_predicted\n\n#Berechnung und Ausgabe der Confusion Matrix\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:23"],"user":["default_user"],"umph":[1499095463.6381],"ok":[true],"chunk":[8],"ex":[1],"e.ind":[0],"code":["\n#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\npos_movie<-DirSource(directory = \"./pos\")\nneg_movie<-DirSource(directory = \"./neg\")\n#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\npos_corpus<-VCorpus(x=pos_movie)\nneg_corpus<-VCorpus(x=neg_movie)\n#Verwendete Trainings- und Testdaten in einem  Vektor zusammenfassen\n#(100 positive und 100 negative Bewertungen)\nfull_corpus<-c(pos_corpus[401:500],neg_corpus[401:500])\n#Den Daten das entsprechende Klassenlabel zuordnen\nsentiment_label <- c(rep(x = \"positive\", times = 100), \n                    rep(x = \"negative\", times = 100))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:30"],"user":["default_user"],"umph":[1499095470.2944],"ok":[true],"chunk":[9],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM mit tfidf-Gewichtung\nDTM_tfidf <- DocumentTermMatrix(full_corpus,\n                              control = list(\n                                stopwords = TRUE,\n                                removeNumbers = TRUE,\n                                removePunctuation = TRUE,\n                                tolower = TRUE,\n                                stripWhitespace = TRUE,                                \n                                stemming = FALSE,\n                                weighting=function(x)\n                                 weightTfIdf(x)))\n\n#Begutachtung des Aufbaus der DTM_tfidf\nprint(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:36"],"user":["default_user"],"umph":[1499095476.2454],"ok":[true],"chunk":[10],"ex":[1],"e.ind":[0],"code":["#Mithilfe der Funktion norm_eucl soll die DTM mit dem euklidischem \n#Distanzmaß normiert werden\nnorm_eucl <- function(x){\n   x/apply(x,1,function(x) sum(x^2)^.5)\n}\n\n#Wenden Sie die Funktion norm_eucl() auf die DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf<-norm_eucl(x=DTM_tfidf)\n\n#Wenden Sie die Funktion as.matrix() auf die neue DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf = as.matrix(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:38"],"user":["default_user"],"umph":[1499095478.8504],"ok":[true],"chunk":[11],"ex":[1],"e.ind":[0],"code":["#Laden des benötigten Packages 'caret', um die nachfolgenden Methoden\n#verwenden zu können\nlibrary(caret)\n\n#Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\nset.seed(1111)\n\n#Elemente des Sentimentlabel-Vektors zufällig in drei Gruppen aufteilen\nindxs<-createFolds(y=sentiment_label,k=3)\n\n#Testdaten gemäß der Aufteilung definieren\ntestset<-DTM_tfidf[indxs[[1]],]\n#Labels der Testdaten\ntestlabels <- sentiment_label[indxs[[1]]]\n\n#Trainingsdaten gemäß der Aufteilung definieren\ntrainingset<- DTM_tfidf[-indxs[[1]],]\n#Labels der Trainingsdaten\ntraininglabels <- sentiment_label[-indxs[[1]]]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:43"],"user":["default_user"],"umph":[1499095483.3551],"ok":[true],"chunk":[12],"ex":[1],"e.ind":[0],"code":["#Der Seed wird gesetzt um im Falle gleich vieler ähnlicher Dokumente\n#verschiedener Klassen die selbe Klassifikation zu erhalten\nset.seed(1111)\n#Wenden Sie die Funktion knn wie oben beschrieben an\n#und speichern Sie das Ergebnis in der Variable knn_predicted_single\nknn_predicted_single <- knn(train = trainingset, test =testset,\n                            cl =  traininglabels, k = 12)\n"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:24:46"],"user":["default_user"],"umph":[1499095486.3757],"ok":[true],"chunk":[13],"ex":[1],"e.ind":[0],"code":["#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":[""]}
,
{"type":["init_ps"],"time":["2017-07-03 17:25:40"],"user":["default_user"],"umph":[1499095540.9991],"ok":[true]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:46"],"user":["default_user"],"umph":[1499095546.0591],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:48"],"user":["default_user"],"umph":[1499095548.4535],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:50"],"user":["default_user"],"umph":[1499095550.7477],"ok":[true],"chunk":[3],"ex":[1],"e.ind":[0],"code":["#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(x=DTM_tf)\n\n#Aufteilung in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:53"],"user":["default_user"],"umph":[1499095553.6736],"ok":[true],"chunk":[4],"ex":[1],"e.ind":[0],"code":["#Verwenden Sie die Funktion naiveBayes(), um mit den Daten aus \n#den Variablen posts_training und posts_traininglabel den Naive Bayes\n#-Klassifikator zu bilden und speichern Sie das Ergebnis in der Variablen\n#nB_classifier\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Verwenden Sie Ihren eben erzeugten Naive Bayes-Klassifikator\n#in der Funktion predict() um die Klassen für die Daten in \n#der Variable posts_test vorherzusagen und speichern Sie Ihr\n#Ergebnis in der Variablen nB_predicted\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Lassen Sie sich das Ergebnis der Klassifikation ausgeben\nnB_predicted"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:56"],"user":["default_user"],"umph":[1499095556.1005],"ok":[true],"chunk":[5],"ex":[1],"e.ind":[0],"code":["#Erzeugen Sie eine Confusion Matrix mit dem Befehl table()\n#und speichern Sie diese in der Variable nB_confMat\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\n#Lassen Sie sich nB_confMat ausgeben\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:57"],"user":["default_user"],"umph":[1499095557.9094],"ok":[true],"chunk":[6],"ex":[1],"e.ind":[0],"code":["#Berechnung von Precision und Recall für die Klasse D\n#Auf Basis der Confusion Matrix\nnB_precision_D <- nB_confMat[1,1]/sum(nB_confMat[,1])\nprint(c(\"Precision für die Klasse Deutsch:\", nB_precision_D))\n\nnB_recall_D <- nB_confMat[1,1]/sum(nB_confMat[1,])\nprint(c(\"Recall für die Klasse Deutsch:\", nB_recall_D))\n\n#Berechnen der F-Measure mit beta = 1 für die Klasse D\n#Auf Basis von Precision und Recall\nbeta <- 1\nnB_F1_D <- ((beta^2+1)*nB_precision_D*nB_recall_D)/(beta^2*nB_precision_D+nB_recall_D)\nprint(c(\"F1-Measure für die Klasse Deutsch:\", nB_F1_D))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:25:59"],"user":["default_user"],"umph":[1499095559.9886],"ok":[true],"chunk":[7],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= stopwords(kind=\"de\"),\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)\n\n#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(DTM_tf)\n\n#Aufteilen in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]\n\n#Erzeugen des Naive Bayes-Klassifikators\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Anwenden des Naive Bayes-Klassifikators auf die Testdaten\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Ausgabe der Ergebnisse der Klassifikation\nnB_predicted\n\n#Berechnung und Ausgabe der Confusion Matrix\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:26:08"],"user":["default_user"],"umph":[1499095568.2736],"ok":[true],"chunk":[8],"ex":[1],"e.ind":[0],"code":["\n#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\npos_movie<-DirSource(directory = \"./pos\")\nneg_movie<-DirSource(directory = \"./neg\")\n#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\npos_corpus<-VCorpus(x=pos_movie)\nneg_corpus<-VCorpus(x=neg_movie)\n#Verwendete Trainings- und Testdaten in einem  Vektor zusammenfassen\n#(100 positive und 100 negative Bewertungen)\nfull_corpus<-c(pos_corpus[401:500],neg_corpus[401:500])\n#Den Daten das entsprechende Klassenlabel zuordnen\nsentiment_label <- c(rep(x = \"positive\", times = 100), \n                    rep(x = \"negative\", times = 100))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:26:14"],"user":["default_user"],"umph":[1499095574.5868],"ok":[true],"chunk":[9],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM mit tfidf-Gewichtung\nDTM_tfidf <- DocumentTermMatrix(full_corpus,\n                              control = list(\n                                stopwords = TRUE,\n                                removeNumbers = TRUE,\n                                removePunctuation = TRUE,\n                                tolower = TRUE,\n                                stripWhitespace = TRUE,                                \n                                stemming = FALSE,\n                                weighting=function(x)\n                                 weightTfIdf(x)))\n\n#Begutachtung des Aufbaus der DTM_tfidf\nprint(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:26:20"],"user":["default_user"],"umph":[1499095580.3141],"ok":[true],"chunk":[10],"ex":[1],"e.ind":[0],"code":["#Mithilfe der Funktion norm_eucl soll die DTM mit dem euklidischem \n#Distanzmaß normiert werden\nnorm_eucl <- function(x){\n   x/apply(x,1,function(x) sum(x^2)^.5)\n}\n\n#Wenden Sie die Funktion norm_eucl() auf die DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf<-norm_eucl(x=DTM_tfidf)\n\n#Wenden Sie die Funktion as.matrix() auf die neue DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf = as.matrix(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:26:22"],"user":["default_user"],"umph":[1499095582.6974],"ok":[true],"chunk":[11],"ex":[1],"e.ind":[0],"code":["#Laden des benötigten Packages 'caret', um die nachfolgenden Methoden\n#verwenden zu können\nlibrary(caret)\n\n#Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\nset.seed(1111)\n\n#Elemente des Sentimentlabel-Vektors zufällig in drei Gruppen aufteilen\nindxs<-createFolds(y=sentiment_label,k=3)\n\n#Testdaten gemäß der Aufteilung definieren\ntestset<-DTM_tfidf[indxs[[1]],]\n#Labels der Testdaten\ntestlabels <- sentiment_label[indxs[[1]]]\n\n#Trainingsdaten gemäß der Aufteilung definieren\ntrainingset<- DTM_tfidf[-indxs[[1]],]\n#Labels der Trainingsdaten\ntraininglabels <- sentiment_label[-indxs[[1]]]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:26:28"],"user":["default_user"],"umph":[1499095588.1442],"ok":[true],"chunk":[12],"ex":[1],"e.ind":[0],"code":["#Der Seed wird gesetzt um im Falle gleich vieler ähnlicher Dokumente\n#verschiedener Klassen die selbe Klassifikation zu erhalten\nset.seed(1111)\n#Wenden Sie die Funktion knn wie oben beschrieben an\n#und speichern Sie das Ergebnis in der Variable knn_predicted_single\nknn_predicted_single <- knn(train = trainingset, test =testset,\n                            cl =  traininglabels, k = 12)\n"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:26:31"],"user":["default_user"],"umph":[1499095591.4249],"ok":[true],"chunk":[13],"ex":[1],"e.ind":[0],"code":["#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":[""]}
,
{"type":["init_ps"],"time":["2017-07-03 17:37:02"],"user":["default_user"],"umph":[1499096222.7704],"ok":[true]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:09"],"user":["default_user"],"umph":[1499096229.8908],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:12"],"user":["default_user"],"umph":[1499096232.5068],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:15"],"user":["default_user"],"umph":[1499096235.0513],"ok":[true],"chunk":[3],"ex":[1],"e.ind":[0],"code":["#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(x=DTM_tf)\n\n#Aufteilung in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:17"],"user":["default_user"],"umph":[1499096237.5131],"ok":[true],"chunk":[4],"ex":[1],"e.ind":[0],"code":["#Verwenden Sie die Funktion naiveBayes(), um mit den Daten aus \n#den Variablen posts_training und posts_traininglabel den Naive Bayes\n#-Klassifikator zu bilden und speichern Sie das Ergebnis in der Variablen\n#nB_classifier\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Verwenden Sie Ihren eben erzeugten Naive Bayes-Klassifikator\n#in der Funktion predict() um die Klassen für die Daten in \n#der Variable posts_test vorherzusagen und speichern Sie Ihr\n#Ergebnis in der Variablen nB_predicted\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Lassen Sie sich das Ergebnis der Klassifikation ausgeben\nnB_predicted"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:20"],"user":["default_user"],"umph":[1499096240.1703],"ok":[true],"chunk":[5],"ex":[1],"e.ind":[0],"code":["#Erzeugen Sie eine Confusion Matrix mit dem Befehl table()\n#und speichern Sie diese in der Variable nB_confMat\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\n#Lassen Sie sich nB_confMat ausgeben\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:22"],"user":["default_user"],"umph":[1499096242.1946],"ok":[true],"chunk":[6],"ex":[1],"e.ind":[0],"code":["#Berechnung von Precision und Recall für die Klasse D\n#Auf Basis der Confusion Matrix\nnB_precision_D <- nB_confMat[1,1]/sum(nB_confMat[,1])\nprint(c(\"Precision für die Klasse Deutsch:\", nB_precision_D))\n\nnB_recall_D <- nB_confMat[1,1]/sum(nB_confMat[1,])\nprint(c(\"Recall für die Klasse Deutsch:\", nB_recall_D))\n\n#Berechnen der F-Measure mit beta = 1 für die Klasse D\n#Auf Basis von Precision und Recall\nbeta <- 1\nnB_F1_D <- ((beta^2+1)*nB_precision_D*nB_recall_D)/(beta^2*nB_precision_D+nB_recall_D)\nprint(c(\"F1-Measure für die Klasse Deutsch:\", nB_F1_D))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:24"],"user":["default_user"],"umph":[1499096244.2702],"ok":[true],"chunk":[7],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= stopwords(kind=\"de\"),\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)\n\n#Format der DTM umwandeln\nDTM_denseMatrix = as.matrix(DTM_tf)\n\n#Aufteilen in Trainingsdaten und Testdaten\nposts_training <- DTM_denseMatrix[1:6,]\nposts_test <- DTM_denseMatrix[7:14,]\n#Abspeichern der Trainingslabels im richtigen Format\nposts_traininglabel <- as.factor(posts[1:6,2])\n#Abspeichern der Testlabels\nposts_testlabel <- posts[7:14,2]\n\n#Erzeugen des Naive Bayes-Klassifikators\nnB_classifier <- naiveBayes(x=posts_training,y=posts_traininglabel)\n#Anwenden des Naive Bayes-Klassifikators auf die Testdaten\nnB_predicted <- predict(object=nB_classifier,newdata=posts_test)\n#Ausgabe der Ergebnisse der Klassifikation\nnB_predicted\n\n#Berechnung und Ausgabe der Confusion Matrix\nnB_confMat <- table(\"Klasse\" = posts_testlabel,\"Klassifiziert als\" = nB_predicted)\nprint(nB_confMat)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:33"],"user":["default_user"],"umph":[1499096253.2041],"ok":[true],"chunk":[8],"ex":[1],"e.ind":[0],"code":["\n#Separates Einlesen der Datensätze für positiv und negativ bewertete Filme\npos_movie<-DirSource(directory = \"./pos\")\nneg_movie<-DirSource(directory = \"./neg\")\n#Speichern der Daten jeweils in einem VCorpus (\"Volatile Corpus\")\npos_corpus<-VCorpus(x=pos_movie)\nneg_corpus<-VCorpus(x=neg_movie)\n#Verwendete Trainings- und Testdaten in einem  Vektor zusammenfassen\n#(100 positive und 100 negative Bewertungen)\nfull_corpus<-c(pos_corpus[401:500],neg_corpus[401:500])\n#Den Daten das entsprechende Klassenlabel zuordnen\nsentiment_label <- c(rep(x = \"positive\", times = 100), \n                    rep(x = \"negative\", times = 100))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:39"],"user":["default_user"],"umph":[1499096259.5972],"ok":[true],"chunk":[9],"ex":[1],"e.ind":[0],"code":["#Erzeugen der DTM mit tfidf-Gewichtung\nDTM_tfidf <- DocumentTermMatrix(full_corpus,\n                              control = list(\n                                stopwords = TRUE,\n                                removeNumbers = TRUE,\n                                removePunctuation = TRUE,\n                                tolower = TRUE,\n                                stripWhitespace = TRUE,                                \n                                stemming = FALSE,\n                                weighting=function(x)\n                                 weightTfIdf(x)))\n\n#Begutachtung des Aufbaus der DTM_tfidf\nprint(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:45"],"user":["default_user"],"umph":[1499096265.2525],"ok":[true],"chunk":[10],"ex":[1],"e.ind":[0],"code":["#Mithilfe der Funktion norm_eucl soll die DTM mit dem euklidischem \n#Distanzmaß normiert werden\nnorm_eucl <- function(x){\n   x/apply(x,1,function(x) sum(x^2)^.5)\n}\n\n#Wenden Sie die Funktion norm_eucl() auf die DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf<-norm_eucl(x=DTM_tfidf)\n\n#Wenden Sie die Funktion as.matrix() auf die neue DTM_tfidf an und\n#speichern Sie das Ergebnis erneut in der Variable DTM_tfidf\n#Um die alte DTM_tfidf zu überschreiben\nDTM_tfidf = as.matrix(DTM_tfidf)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:48"],"user":["default_user"],"umph":[1499096268.2545],"ok":[true],"chunk":[11],"ex":[1],"e.ind":[0],"code":["#Laden des benötigten Packages 'caret', um die nachfolgenden Methoden\n#verwenden zu können\nlibrary(caret)\n\n#Der Seed wird gesetzt um reproduzierbare Aufteilungen zu erzeugen\nset.seed(1111)\n\n#Elemente des Sentimentlabel-Vektors zufällig in drei Gruppen aufteilen\nindxs<-createFolds(y=sentiment_label,k=3)\n\n#Testdaten gemäß der Aufteilung definieren\ntestset<-DTM_tfidf[indxs[[1]],]\n#Labels der Testdaten\ntestlabels <- sentiment_label[indxs[[1]]]\n\n#Trainingsdaten gemäß der Aufteilung definieren\ntrainingset<- DTM_tfidf[-indxs[[1]],]\n#Labels der Trainingsdaten\ntraininglabels <- sentiment_label[-indxs[[1]]]"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:53"],"user":["default_user"],"umph":[1499096273.8554],"ok":[true],"chunk":[12],"ex":[1],"e.ind":[0],"code":["#Der Seed wird gesetzt um im Falle gleich vieler ähnlicher Dokumente\n#verschiedener Klassen die selbe Klassifikation zu erhalten\nset.seed(1111)\n#Wenden Sie die Funktion knn wie oben beschrieben an\n#und speichern Sie das Ergebnis in der Variable knn_predicted_single\nknn_predicted_single <- knn(train = trainingset, test =testset,\n                            cl =  traininglabels, k = 12)\n"],"message":[""]}
,
{"type":["check_chunk"],"time":["2017-07-03 17:37:57"],"user":["default_user"],"umph":[1499096277.0383],"ok":[true],"chunk":[13],"ex":[1],"e.ind":[0],"code":["#Tabelle mit \"richtigen\" und vorhergesagten Werten ausgeben\nknn_confMat_single <- table(\"Klasse\" = testlabels, \n                            \"Klassifiziert als\" = knn_predicted_single)\nprint(knn_confMat_single)\n\n#Precision der Klasse \"positive\" berechnen\nknn_precision_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[,2])\nprint(c(\"Precision:\", knn_precision_pos_single))\n\n#Recall der Klasse \"positive\" berechnen\nknn_recall_pos_single <- knn_confMat_single[2,2]/sum(knn_confMat_single[2,])\nprint(c(\"Recall:\", knn_recall_pos_single))\n    \n#F-1 Measure mit beta = 1 der Klasse \"positive\" berechnen\nbeta <- 1\nknn_F1_pos_single <- ((beta^2+1)*knn_precision_pos_single*knn_recall_pos_single)/(beta^2*knn_precision_pos_single+knn_recall_pos_single)\nprint(c(\"F1-Measure:\", knn_F1_pos_single))"],"message":[""]}
,
{"type":["init_ps"],"time":["2018-04-11 23:48:40"],"user":["default_user"],"umph":[1523483320.0907],"ok":[true]}
,
{"type":["check_chunk"],"time":["2018-04-11 23:48:56"],"user":["default_user"],"umph":[1523483336.1046],"ok":[true],"chunk":[1],"ex":[1],"e.ind":[0],"code":["#Laden des Packages 'tm', um Methoden des Text Mining verwenden zu können\nlibrary(tm)\n#Laden der Posts mit der zugehörigen Klasse\nposts <-  rbind(\n  c('Wenn ich meine Freundin zum Essen einlade, gehen wir meistens\n     zum Italiener um die Ecke. Dort gibt es nicht nur die beste \n     Pizza der Stadt, sondern auch einen super leckeren Wein','I'),\n  c('Mein Lieblingsrestaurant hat eine gut bürgerliche Küche.\n     Hier esse ich am liebsten Schnitzel und trinke dazu ein \n     Bier.','D'),\n  c('Pizza und Wein und alles ist fein!','I'),\n  c('Ich mag italienische Pizza und vor allem Wein','I'),\n  c('Für mich besteht ein gutes Essen aus einem großen Schnitzel\n     und dazu gehört auch ein Bier','D'),\n  c('Stimme ich zu, ein gutes Restaurant hat für mich Schnitzel \n     und Bier','D'),\n  c('Pizza, Pasta, Salat, egal wichtig ist italienische Küche!\n     Ein guter Wein darf auch nicht fehlen.','I'),\n  c('Das seh ich genau so. Wenn ich im Restaurant bin braucht\n     es auf jeden Fall einen guten Wein und einen Salat als Vorspeise.\n     Ob dann Pizza oder Pasta ist mir egal','I'),\n  c('Ich gehe nur deutsch Essen. Wenn ich im Restaurant bin dann\n     braucht es Schnitzel und Bier, das reicht!','D'),\n  c('Schnitzel in allen Varianten und Bier vom Fass, das muss ein\n     gutes Restaurant zu bieten haben','D'),\n  c('Wein ist super und nichts geht über Pizza! Nur mit Salat kann\n     ich nichts anfangen','I'),\n  c('In einem deutschen Restaurant bestelle ich mir zu einem panierten\n     Schnitzel ein Bier vom Fass','D'),\n  c('Am liebsten sitze ich im Sommer bei meinem Lieblingsitaliener\n     draußen bei einem Glas Wein und einer Pizza','I'),\n  c('Ach was, Bier und Schnitzel das ist es! Hauptsache deutsch!','D')\n  )\n\n#Einlesen der Posts in einen Corpus\n#zur Erzeugung der DTM\nposts_corpus <- VCorpus(VectorSource(posts[,1]))"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-04-11 23:49:06"],"user":["default_user"],"umph":[1523483346.5318],"ok":[true],"chunk":[2],"ex":[1],"e.ind":[0],"code":["#Erstellen der Document Term Matrix\nDTM_tf <- DocumentTermMatrix(x=posts_corpus,\n                             control=list(\n                               stopwords= FALSE,\n                               removeNumbers=TRUE,\n                               removePunctuation=TRUE,\n                               tolower=TRUE,\n                               stripWhitespace=TRUE,\n                               stemming=FALSE))\n\n#Begutachten der DTM\ninspect(x=DTM_tf)"],"message":[""]}
,
{"type":["init_ps"],"time":["2018-04-11 23:52:43"],"user":["default_user"],"umph":[1523483563.0477],"ok":[true]}
,
{"type":["init_ps"],"time":["2018-04-11 23:56:12"],"user":["default_user"],"umph":[1523483772.8481],"ok":[true]}
,
